{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "testBLTK.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y99WXEOV0h_",
        "colab_type": "text"
      },
      "source": [
        "# Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKul6dFJ4YV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "outputId": "8e255153-fbc2-42d7-ed21-d150351a39fc"
      },
      "source": [
        "pip install bltk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/17/d9/d8000e8cf8f5df6d39615266b529174e95046b34da1c88636d855c1b16c3/bltk-1.2.tar.gz (17.4MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4MB 242kB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn>=0.0 in /usr/local/lib/python3.6/dist-packages (from bltk) (0.0)\n",
            "Collecting six>=1.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from bltk) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from bltk) (0.22.1)\n",
            "Collecting numpy>=1.18.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/20/4d43e141b5bc426ba38274933ef8e76e85c7adea2c321ecf9ebf7421cedf/numpy-1.18.1-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.2MB 198kB/s \n",
            "\u001b[?25hCollecting nltk>=3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from bltk) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2019.11.28 in /usr/local/lib/python3.6/dist-packages (from bltk) (2019.11.28)\n",
            "Building wheels for collected packages: bltk, nltk\n",
            "  Building wheel for bltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bltk: filename=bltk-1.2-cp36-none-any.whl size=17432536 sha256=048ce3715c04e34c98d7a7e245f84a6f3f837932526f49b94aa1f7e424055db6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8d/a2/28/31c169557c41c3c6c2227874781112102bd01578931f35803f\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449906 sha256=f3d2ef6462b1e09c2dc32e603166a1ada508090dde189443a9c5a13e0e4e5596\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built bltk nltk\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.14.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, numpy, nltk, bltk\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "  Found existing installation: numpy 1.17.5\n",
            "    Uninstalling numpy-1.17.5:\n",
            "      Successfully uninstalled numpy-1.17.5\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed bltk-1.2 nltk-3.4.5 numpy-1.18.1 six-1.14.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_8F1eRbWvHh",
        "colab_type": "text"
      },
      "source": [
        "# Bangla Characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cue9hrVKCET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "fa28a22c-58bc-4f69-b92b-42984be693b9"
      },
      "source": [
        "from bltk.langtools.banglachars import (vowels,\n",
        "                                        vowel_signs,\n",
        "                                        consonants,\n",
        "                                        digits,\n",
        "                                        operators,\n",
        "                                        punctuations,\n",
        "                                        others)\n",
        "print(f'Vowels: {vowels}')\n",
        "print(f'Vowel signs: {vowel_signs}')\n",
        "print(f'Consonants: {consonants}')\n",
        "print(f'Digits: {digits}')\n",
        "print(f'Operators: {operators}')\n",
        "print(f'Punctuation marks: {punctuations}')\n",
        "print(f'Others: {others}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vowels: ['অ', 'আ', 'ই', 'ঈ', 'উ', 'ঊ', 'ঋ', 'ঌ', 'এ', 'ঐ', 'ও', 'ঔ']\n",
            "Vowel signs: ['া', 'ি', 'ী', 'ু', 'ূ', 'ৃ', 'ৄ', 'ে', 'ৈ', 'ো', 'ৌ']\n",
            "Consonants: ['ক', 'খ', 'গ', 'ঘ', 'ঙ', 'চ', 'ছ', 'জ', 'ঝ', 'ঞ', 'ট', 'ঠ', 'ড', 'ঢ', 'ণ', 'ত', 'থ', 'দ', 'ধ', 'ন', 'প', 'ফ', 'ব', 'ভ', 'ম', 'য', 'র', 'ল', 'শ', 'ষ', 'স', 'হ', 'ড়', 'ঢ়', 'য়', 'ৎ', 'ং', 'ঃ', 'ঁ']\n",
            "Digits: ['০', '১', '২', '৩', '৪', '৫', '৬', '৭', '৮', '৯']\n",
            "Operators: ['=', '+', '-', '*', '/', '%', '<', '>', '×', '÷']\n",
            "Punctuation marks: ['।', ',', ';', ':', '?', '!', \"'\", '.', '\"', '-', '[', ']', '{', '}', '(', ')', '–', '—', '―', '~']\n",
            "Others: ['৳', '৺', '্', 'ঀ', 'ঽ', '#', '$']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-d5b0dcWzti",
        "colab_type": "text"
      },
      "source": [
        "# Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9tfIQvOWz0R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "6413d7aa-4792-40e3-d2a9-0d32ce6e08d3"
      },
      "source": [
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "# Sample text\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \"\\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "# Creating an instance\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Tokenizing words\n",
        "print('TOKENIZED WORDS')\n",
        "words = tokenizer.word_tokenizer(text)\n",
        "print(words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOKENIZED WORDS\n",
            "['আমি', 'জানি', 'আমার', 'এই', 'লেখাটির', 'জন্য', 'আমাকে', 'অনেক', 'গালমন্দ', 'শুনতে', 'হবে', ',', 'তারপরেও', 'লিখছি', '।', 'লিখে', 'খুব', 'কাজ', 'হয়', 'সে', 'রকম', 'উদাহরণ', 'আমার', 'হাতে', 'খুব', 'বেশী', 'নেই', 'কিন্তু', 'অন্তত', 'নিজের', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'করা', 'যায়', 'সেটাই', 'আমার', 'জন্যে', 'অনেক', '।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDRE_MagXEkO",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sy2pF_4SXErV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "624a219f-145a-4b59-cfb3-7731ab9f61dc"
      },
      "source": [
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "# Sample text\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "# Creating an instance\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "\n",
        "# Tokenizing Sentences\n",
        "print(\"TOKENIZED SENTENCES\")\n",
        "sentences = tokenizer.sentence_tokenizer(text)\n",
        "print(sentences)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOKENIZED SENTENCES\n",
            "['আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি।', 'লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা যায় সেটাই আমার জন্যে অনেক।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6GZLS6FXYs2",
        "colab_type": "text"
      },
      "source": [
        "# Sentence Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZehsmHvHXY6N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "d642037f-5409-4172-d90d-255e8e46b2bf"
      },
      "source": [
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "# Sample text\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "# Creating an instance\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "\n",
        "# Tokenizing Sentences\n",
        "sentences = tokenizer.sentence_tokenizer(text)\n",
        "\n",
        "print(\"SPLIT SENTENCES\")\n",
        "sentence_list = tokenizer.sentence_splitter(sentences)\n",
        "print(sentence_list)\n",
        "\n",
        "print(\"INDIVIDUAL SENTENCE\")\n",
        "for i in sentence_list:\n",
        "    print(i)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SPLIT SENTENCES\n",
            "[['আমি', 'জানি', 'আমার', 'এই', 'লেখাটির', 'জন্য', 'আমাকে', 'অনেক', 'গালমন্দ', 'শুনতে', 'হবে', ',', 'তারপরেও', 'লিখছি', '।'], ['লিখে', 'খুব', 'কাজ', 'হয়', 'সে', 'রকম', 'উদাহরণ', 'আমার', 'হাতে', 'খুব', 'বেশী', 'নেই', 'কিন্তু', 'অন্তত', 'নিজের', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'করা', 'যায়', 'সেটাই', 'আমার', 'জন্যে', 'অনেক', '।']]\n",
            "INDIVIDUAL SENTENCE\n",
            "['আমি', 'জানি', 'আমার', 'এই', 'লেখাটির', 'জন্য', 'আমাকে', 'অনেক', 'গালমন্দ', 'শুনতে', 'হবে', ',', 'তারপরেও', 'লিখছি', '।']\n",
            "['লিখে', 'খুব', 'কাজ', 'হয়', 'সে', 'রকম', 'উদাহরণ', 'আমার', 'হাতে', 'খুব', 'বেশী', 'নেই', 'কিন্তু', 'অন্তত', 'নিজের', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'করা', 'যায়', 'সেটাই', 'আমার', 'জন্যে', 'অনেক', '।']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfoP_1GRXq-m",
        "colab_type": "text"
      },
      "source": [
        "# Stopwords Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_VIuE-XrGQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "dcf114d8-e65c-4a01-d9a1-21109ae0ef5a"
      },
      "source": [
        "from bltk.langtools import remove_stopwords\n",
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "tokened_words = tokenizer.word_tokenizer(text)\n",
        "\n",
        "print(f\"Len of words: {len(tokened_words)}\")\n",
        "print(f\"After soft elimination: {(remove_stopwords(tokened_words))}\")\n",
        "print(f\"Length after soft elimination: {len(remove_stopwords(tokened_words))}\")\n",
        "print(f\"After moderate elimination: {(remove_stopwords(tokened_words, level='moderate'))}\")\n",
        "print(f\"Length after moderate elimination: {len(remove_stopwords(tokened_words, level='moderate'))}\")\n",
        "print(f\"After hard elimination: {(remove_stopwords(tokened_words, level='hard'))}\")\n",
        "print(f\"Length after hard elimination: {len(remove_stopwords(tokened_words, level='hard'))}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Len of words: 40\n",
            "After soft elimination: ['জানি', 'লেখাটির', 'অনেক', 'গালমন্দ', 'শুনতে', 'তারপরেও', 'লিখছি', 'লিখে', 'কাজ', 'রকম', 'উদাহরণ', 'হাতে', 'বেশী', 'অন্তত', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'করা', 'সেটাই', 'অনেক']\n",
            "Length after soft elimination: 20\n",
            "After moderate elimination: ['জানি', 'লেখাটির', 'গালমন্দ', 'শুনতে', 'তারপরেও', 'লিখছি', 'লিখে', 'উদাহরণ', 'হাতে', 'বেশী', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'যায়', 'জন্যে']\n",
            "Length after moderate elimination: 15\n",
            "After hard elimination: ['জানি', 'লেখাটির', 'গালমন্দ', 'শুনতে', 'তারপরেও', 'লিখছি', 'লিখে', 'উদাহরণ', 'হাতে', 'বেশী', 'ভেতরের', 'ক্ষোভটুকু', 'বের']\n",
            "Length after hard elimination: 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D8rt4VJX1z2",
        "colab_type": "text"
      },
      "source": [
        "# Part-of-speech Tagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elZFJvhVX1_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2e09793b-b475-410a-c4fe-ff26c7112445"
      },
      "source": [
        "from bltk.langtools import PosTagger\n",
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "pos_tagger = PosTagger()\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "token_text = tokenizer.sentence_tokenizer(text)\n",
        "\n",
        "\n",
        "pos_tags = []\n",
        "for text in token_text:\n",
        "    tokened = tokenizer.word_tokenizer(text)\n",
        "    tagged = pos_tagger.pos_tag(tokened)\n",
        "    pos_tags.append(tagged)\n",
        "print(pos_tags)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[('আমি', 'PPR'), ('জানি', 'VM'), ('আমার', 'PPR'), ('এই', 'DAB'), ('লেখাটির', 'NC'), ('জন্য', 'PP'), ('আমাকে', 'PPR'), ('অনেক', 'JQ'), ('গালমন্দ', 'NC'), ('শুনতে', 'VM'), ('হবে', 'VA'), (',', 'PU'), ('তারপরেও', 'ALC'), ('লিখছি', 'VM'), ('।', 'PU')], [('লিখে', 'VM'), ('খুব', 'JQ'), ('কাজ', 'NC'), ('হয়', 'VM'), ('সে', 'PPR'), ('রকম', 'NC'), ('উদাহরণ', 'NC'), ('আমার', 'PPR'), ('হাতে', 'NC'), ('খুব', 'JQ'), ('বেশী', 'JJ'), ('নেই', 'VM'), ('কিন্তু', 'CSB'), ('অন্তত', 'CSB'), ('নিজের', 'PRF'), ('ভেতরের', 'NST'), ('ক্ষোভটুকু', 'NC'), ('বের', 'VM'), ('করা', 'NV'), ('যায়', 'VM'), ('সেটাই', 'PPR'), ('আমার', 'PPR'), ('জন্যে', 'PP'), ('অনেক', 'JQ'), ('।', 'PU')]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.dict_vectorizer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction. Anything that cannot be imported from sklearn.feature_extraction is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.linear_model.logistic module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.linear_model. Anything that cannot be imported from sklearn.linear_model is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ib4on9j8YHMf",
        "colab_type": "text"
      },
      "source": [
        "# Noun Phrase Chunking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BnY40mYYHU4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "f7406b9f-7e3b-4363-c2a1-f778eb5dc136"
      },
      "source": [
        "from bltk.langtools import Tokenizer\n",
        "from bltk.langtools import Chunker\n",
        "\n",
        "\n",
        "grammar = r\"\"\"\n",
        "  NP: {<DAB>?<JJ|JQ>*<N.>}      \n",
        "  \"\"\"\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "sentences = tokenizer.sentence_tokenizer(text)\n",
        "tokened_text = [tokenizer.word_tokenizer(sentence) for sentence in sentences]\n",
        "\n",
        "noun_phrases = []\n",
        "for t in tokened_text:\n",
        "    chunky = Chunker(grammar=grammar, tokened_text=t)\n",
        "    chunk_tree = chunky.chunk()\n",
        "    for i in chunk_tree.subtrees():\n",
        "        if i.label() == \"NP\":\n",
        "            print(i)\n",
        "            noun_phrases.append(i)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(NP এই/DAB লেখাটির/NC)\n",
            "(NP অনেক/JQ গালমন্দ/NC)\n",
            "(NP খুব/JQ কাজ/NC)\n",
            "(NP রকম/NC)\n",
            "(NP উদাহরণ/NC)\n",
            "(NP হাতে/NC)\n",
            "(NP ক্ষোভটুকু/NC)\n",
            "(NP করা/NV)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weufg5L6YVFx",
        "colab_type": "text"
      },
      "source": [
        "# Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7gorqzVYVSr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "e3df7df5-d6e2-41c3-da7d-ca1412eded67"
      },
      "source": [
        "from bltk.langtools import UgraStemmer\n",
        "from bltk.langtools import Tokenizer\n",
        "\n",
        "\n",
        "text = \"আমি জানি আমার এই লেখাটির জন্য আমাকে অনেক গালমন্দ শুনতে হবে, তারপরেও লিখছি। \" \\\n",
        "       \"লিখে খুব কাজ হয় সে রকম উদাহরণ আমার হাতে খুব বেশী নেই কিন্তু অন্তত নিজের ভেতরের ক্ষোভটুকু বের করা \" \\\n",
        "       \"যায় সেটাই আমার জন্যে অনেক।\"\n",
        "\n",
        "stemmer = UgraStemmer()\n",
        "tokenizer = Tokenizer()\n",
        "tokenized_text = tokenizer.word_tokenizer(text)\n",
        "\n",
        "stem = stemmer.stem(tokenized_text)\n",
        "\n",
        "print(f\"Before stemming: {tokenized_text}\")\n",
        "print(f'After stemming: {stem}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before stemming: ['আমি', 'জানি', 'আমার', 'এই', 'লেখাটির', 'জন্য', 'আমাকে', 'অনেক', 'গালমন্দ', 'শুনতে', 'হবে', ',', 'তারপরেও', 'লিখছি', '।', 'লিখে', 'খুব', 'কাজ', 'হয়', 'সে', 'রকম', 'উদাহরণ', 'আমার', 'হাতে', 'খুব', 'বেশী', 'নেই', 'কিন্তু', 'অন্তত', 'নিজের', 'ভেতরের', 'ক্ষোভটুকু', 'বের', 'করা', 'যায়', 'সেটাই', 'আমার', 'জন্যে', 'অনেক', '।']\n",
            "After stemming: ['আমি', 'জানি', 'আমি', 'এই', 'লেখা', 'জন্য', 'আমি', 'অনেক', 'গালমন্দ', 'শুনতে', 'হবে', ',', 'তারপরে', 'লিখছি', '।', 'লিখে', 'খুব', 'কাজ', 'হয়', 'সে', 'রকম', 'উদাহরণ', 'আমি', 'হাতে', 'খুব', 'বেশ', 'নে', 'কিন্তু', 'অন্তত', 'নিজের', 'ভেতর', 'ক্ষোভ', 'বের', 'করা', 'যায়', 'সেটি', 'আমি', 'জন্যে', 'অনেক', '।']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator DictVectorizer from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator LogisticRegression from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.21.3 when using version 0.22.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}